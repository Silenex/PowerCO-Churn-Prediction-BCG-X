{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb093050",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# TASK 3 - FEATURE ENGINEERING & MODELLING (BCGX Forage - PowerCo churn)\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46263ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd9da69",
   "metadata": {},
   "source": [
    "## -------------------------\n",
    "## 1) Load data + parse dates\n",
    "## -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f557fed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_data: (14606, 26) | price_data: (193002, 8)\n"
     ]
    }
   ],
   "source": [
    "client_path = r\"C:/Users/Utente/Desktop/BCG X (PER ME)/Task 2 Exploration Data Analysis (EDA)/client_data.csv\"\n",
    "price_path  = r\"C:/Users/Utente/Desktop/BCG X (PER ME)/Task 2 Exploration Data Analysis (EDA)/price_data.csv\"\n",
    "\n",
    "client_data = pd.read_csv(client_path)\n",
    "price_data  = pd.read_csv(price_path)\n",
    "\n",
    "date_cols_client = [\"date_activ\", \"date_end\", \"date_modif_prod\", \"date_renewal\"]\n",
    "for col in date_cols_client:\n",
    "    if col in client_data.columns:\n",
    "        client_data[col] = pd.to_datetime(client_data[col], errors=\"coerce\")\n",
    "\n",
    "price_data[\"price_date\"] = pd.to_datetime(price_data[\"price_date\"], errors=\"coerce\")\n",
    "\n",
    "print(\"client_data:\", client_data.shape, \"| price_data:\", price_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee051e28",
   "metadata": {},
   "source": [
    "## -------------------------\n",
    "## 2) Config\n",
    "## -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb97783",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = pd.Timestamp(\"2015-12-31\")\n",
    "LEAK_COLS = [\"dev_consum_no_churn\", \"dev_consum_with_log\"]\n",
    "USE_FORECAST = False  # nel modelling potrai fare ablation\n",
    "\n",
    "def sanitize_inf(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype != \"object\":\n",
    "            df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b8fbb5",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------\n",
    "## 3) Remove columns (costanti + leakage by construction + forecast_*)\n",
    "## ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6239a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped forecast cols: 7\n"
     ]
    }
   ],
   "source": [
    "const_cols = [c for c in client_data.columns if client_data[c].nunique(dropna=False) <= 1]\n",
    "if const_cols:\n",
    "    client_data = client_data.drop(columns=const_cols)\n",
    "    print(\"Dropped constant client cols:\", const_cols)\n",
    "\n",
    "leak_in_client = [c for c in LEAK_COLS if c in client_data.columns]\n",
    "if leak_in_client:\n",
    "    client_data = client_data.drop(columns=leak_in_client)\n",
    "    print(\"Dropped leak cols from client_data:\", leak_in_client)\n",
    "\n",
    "if not USE_FORECAST:\n",
    "    forecast_cols = [c for c in client_data.columns if c.startswith(\"forecast_\")]\n",
    "    if forecast_cols:\n",
    "        client_data = client_data.drop(columns=forecast_cols)\n",
    "        print(\"Dropped forecast cols:\", len(forecast_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fa7494",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------\n",
    "## 4) Feature Engineering - price features (as-of T)\n",
    "## ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa30b840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price_feat: (16096, 28)\n"
     ]
    }
   ],
   "source": [
    "PRICE_VARS = [\n",
    "    \"price_off_peak_var\", \"price_peak_var\", \"price_mid_peak_var\",\n",
    "    \"price_off_peak_fix\", \"price_peak_fix\", \"price_mid_peak_fix\",\n",
    "]\n",
    "\n",
    "p = price_data.dropna(subset=[\"price_date\"]).copy()\n",
    "p = p[p[\"price_date\"] <= T].sort_values([\"id\", \"price_date\"])\n",
    "\n",
    "def make_price_features(df_id: pd.DataFrame) -> pd.Series:\n",
    "    df_id = df_id.sort_values(\"price_date\")\n",
    "    last = df_id.iloc[-1]\n",
    "    out = {}\n",
    "\n",
    "    for v in PRICE_VARS:\n",
    "        out[f\"{v}_last\"] = last[v]\n",
    "        out[f\"{v}_mean\"] = df_id[v].mean()\n",
    "        out[f\"{v}_std\"]  = df_id[v].std()\n",
    "\n",
    "        y = pd.to_numeric(df_id[v], errors=\"coerce\").to_numpy()\n",
    "        x = np.arange(len(y), dtype=float)\n",
    "        if len(y) >= 3 and np.isfinite(y).sum() >= 3:\n",
    "            out[f\"{v}_slope\"] = np.polyfit(x, y, 1)[0]\n",
    "        else:\n",
    "            out[f\"{v}_slope\"] = np.nan\n",
    "\n",
    "    out[\"var_peak_minus_offpeak_last\"] = last[\"price_peak_var\"] - last[\"price_off_peak_var\"]\n",
    "    out[\"fix_peak_minus_offpeak_last\"] = last[\"price_peak_fix\"] - last[\"price_off_peak_fix\"]\n",
    "    out[\"var_peak_over_offpeak_last\"]  = (\n",
    "        (last[\"price_peak_var\"] / last[\"price_off_peak_var\"])\n",
    "        if pd.notna(last[\"price_off_peak_var\"]) and last[\"price_off_peak_var\"] != 0\n",
    "        else np.nan\n",
    "    )\n",
    "    return pd.Series(out)\n",
    "\n",
    "try:\n",
    "    price_feat = p.groupby(\"id\").apply(make_price_features, include_groups=False).reset_index()\n",
    "except TypeError:\n",
    "    price_feat = p.groupby(\"id\").apply(make_price_features).reset_index()\n",
    "\n",
    "print(\"price_feat:\", price_feat.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f6740",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------\n",
    "## 5) Feature Engineering - time-derived client features (as-of T)\n",
    "## ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec68691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = client_data.copy()\n",
    "\n",
    "c[\"tenure_days\"] = (T - c[\"date_activ\"]).dt.days\n",
    "c[\"days_since_prod_modif\"] = (T - c[\"date_modif_prod\"]).dt.days\n",
    "c[\"days_to_renewal\"] = (c[\"date_renewal\"] - T).dt.days\n",
    "\n",
    "# SAFE dev_consum for everyone (NOT conditional on churn)\n",
    "c[\"dev_consum\"] = c[\"cons_last_month\"] - (c[\"cons_12m\"] / 12.0)\n",
    "\n",
    "# In Task 4 droppiamo le date raw; qui le teniamo o le droppiamo: scegliamo di dropparle già ora.\n",
    "date_cols_present = [col for col in date_cols_client if col in c.columns]\n",
    "c = c.drop(columns=date_cols_present)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ccc2e",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------\n",
    "## 6) Combine datasets (merge finale) -> df feature-ready\n",
    "## ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7faad47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df feature-ready: (14606, 46)\n"
     ]
    }
   ],
   "source": [
    "df = c.merge(price_feat, on=\"id\", how=\"left\")\n",
    "df = sanitize_inf(df)\n",
    "\n",
    "print(\"df feature-ready:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf3d77e",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------\n",
    "## 7) Sanity checks finali (ready to model)\n",
    "## ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0912007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SANITY CHECKS ---\n",
      "                                 id                     channel_sales  \\\n",
      "0  24011ae4ebbe3035111d65fa7c15bc57  foosdfpfkusacimwkcsosbicdxkicaua   \n",
      "1  d29c2c54acc38ff3c0614d0a653813dd                           MISSING   \n",
      "2  764c75f661154dac3a6c254cd082ea7d  foosdfpfkusacimwkcsosbicdxkicaua   \n",
      "\n",
      "   cons_12m  cons_gas_12m  cons_last_month has_gas  imp_cons  \\\n",
      "0         0         54946                0       t       0.0   \n",
      "1      4660             0                0       f       0.0   \n",
      "2       544             0                0       f       0.0   \n",
      "\n",
      "   margin_gross_pow_ele  margin_net_pow_ele  nb_prod_act  ...  \\\n",
      "0                 25.44               25.44            2  ...   \n",
      "1                 16.38               16.38            1  ...   \n",
      "2                 28.60               28.60            1  ...   \n",
      "\n",
      "   price_peak_fix_mean  price_peak_fix_std price_peak_fix_slope  \\\n",
      "0             22.35201            7.039226            -0.927593   \n",
      "1              0.00000            0.000000             0.000000   \n",
      "2              0.00000            0.000000             0.000000   \n",
      "\n",
      "   price_mid_peak_fix_last  price_mid_peak_fix_mean  price_mid_peak_fix_std  \\\n",
      "0                      0.0                 14.90134                4.692817   \n",
      "1                      0.0                  0.00000                0.000000   \n",
      "2                      0.0                  0.00000                0.000000   \n",
      "\n",
      "   price_mid_peak_fix_slope  var_peak_minus_offpeak_last  \\\n",
      "0                 -0.618395                    -0.060550   \n",
      "1                  0.000000                    -0.147600   \n",
      "2                  0.000000                    -0.079389   \n",
      "\n",
      "   fix_peak_minus_offpeak_last  var_peak_over_offpeak_last  \n",
      "0                    -44.26693                    0.585368  \n",
      "1                    -44.44471                    0.000000  \n",
      "2                    -44.44471                    0.526878  \n",
      "\n",
      "[3 rows x 46 columns]\n",
      "\n",
      "Missing rate (top 15):\n",
      "var_peak_over_offpeak_last    0.00178\n",
      "id                            0.00000\n",
      "cons_12m                      0.00000\n",
      "cons_gas_12m                  0.00000\n",
      "cons_last_month               0.00000\n",
      "channel_sales                 0.00000\n",
      "imp_cons                      0.00000\n",
      "margin_gross_pow_ele          0.00000\n",
      "margin_net_pow_ele            0.00000\n",
      "nb_prod_act                   0.00000\n",
      "net_margin                    0.00000\n",
      "num_years_antig               0.00000\n",
      "origin_up                     0.00000\n",
      "has_gas                       0.00000\n",
      "pow_max                       0.00000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- SANITY CHECKS ---\")\n",
    "print(df.head(3))\n",
    "print(\"\\nMissing rate (top 15):\")\n",
    "print(df.isna().mean().sort_values(ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85f0499",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# TASK 4 - MODELLING\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "debf6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.inspection import permutation_importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb8cff6",
   "metadata": {},
   "source": [
    "## -------------------------\n",
    "## Config modelling\n",
    "## -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "064cf0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.25\n",
    "TOPK_FRAC = 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b19a97",
   "metadata": {},
   "source": [
    "## -------------------------\n",
    "## Helper: precision/recall@k\n",
    "## -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92503742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(y_true, y_score, k_frac=0.10):\n",
    "    y_true = pd.Series(y_true).reset_index(drop=True)\n",
    "    y_score = pd.Series(y_score).reset_index(drop=True)\n",
    "    n = len(y_true)\n",
    "    k = max(1, int(n * k_frac))\n",
    "    idx = np.argsort(-y_score)[:k]\n",
    "    precision = y_true.iloc[idx].mean()\n",
    "    recall = y_true.iloc[idx].sum() / y_true.sum()\n",
    "    return float(precision), float(recall), k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e405053f",
   "metadata": {},
   "source": [
    "## -------------------------\n",
    "## Helper: preprocess builders\n",
    "## -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5df5f65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preprocess(X):\n",
    "    cat_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "    num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols),\n",
    "            (\"cat\", Pipeline([\n",
    "                (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "            ]), cat_cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def build_preprocess_lr(X):\n",
    "    cat_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "    num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", Pipeline([\n",
    "                (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                (\"scaler\", StandardScaler(with_mean=False))\n",
    "            ]), num_cols),\n",
    "            (\"cat\", Pipeline([\n",
    "                (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "            ]), cat_cols),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f86743d",
   "metadata": {},
   "source": [
    "## -------------------------\n",
    "## Costruzione X,y (da df feature-ready)\n",
    "## -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e9b7bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (14606, 44) | churn rate: 0.09715185540188963\n"
     ]
    }
   ],
   "source": [
    "y = df[\"churn\"].astype(int)\n",
    "\n",
    "exclude = set([\"id\", \"churn\"])\n",
    "if not USE_FORECAST:\n",
    "    exclude |= set([c for c in df.columns if c.startswith(\"forecast_\")])\n",
    "\n",
    "X = df[[c for c in df.columns if c not in exclude]].copy()\n",
    "X = X.drop(columns=[c for c in LEAK_COLS if c in X.columns], errors=\"ignore\")\n",
    "X = sanitize_inf(X)\n",
    "\n",
    "print(\"X:\", X.shape, \"| churn rate:\", float(y.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edfbc9e",
   "metadata": {},
   "source": [
    "## -------------------------\n",
    "## Log-transform (solo su X_log)\n",
    "## -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b179f435",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_COLS = [\"cons_12m\",\"cons_gas_12m\",\"cons_last_month\",\"imp_cons\",\n",
    "            \"margin_gross_pow_ele\",\"margin_net_pow_ele\",\"pow_max\",\"dev_consum\"]\n",
    "\n",
    "LOG_COLS = [c for c in LOG_COLS if c in X.columns]\n",
    "\n",
    "X_log = X.copy()\n",
    "for col in LOG_COLS:\n",
    "    X_log[col] = np.log1p(pd.to_numeric(X_log[col], errors=\"coerce\").clip(lower=0))\n",
    "\n",
    "# NB: NON logghiamo net_margin perché serve raw nel business case.\n",
    "# Se vuoi loggarlo per il modello, crea net_margin_log separato:\n",
    "if \"net_margin\" in X_log.columns:\n",
    "    X_log[\"net_margin_log\"] = np.log1p(pd.to_numeric(X_log[\"net_margin\"], errors=\"coerce\").clip(lower=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8ff38",
   "metadata": {},
   "source": [
    "## -------------------------\n",
    "## Train/eval function\n",
    "## -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6ee2834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_models(X_in, y_in, random_state=42, test_size=0.25, topk_frac=0.10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_in, y_in, test_size=test_size, random_state=random_state, stratify=y_in\n",
    "    )\n",
    "\n",
    "    preprocess_rf = build_preprocess(X_train)\n",
    "    preprocess_lr = build_preprocess_lr(X_train)\n",
    "\n",
    "    logreg = Pipeline(steps=[\n",
    "        (\"prep\", preprocess_lr),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            max_iter=5000,\n",
    "            class_weight=\"balanced\",\n",
    "            solver=\"saga\",\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    rf = Pipeline(steps=[\n",
    "        (\"prep\", preprocess_rf),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            n_estimators=400,\n",
    "            random_state=random_state,\n",
    "            class_weight=\"balanced_subsample\",\n",
    "            n_jobs=-1,\n",
    "            min_samples_leaf=5,\n",
    "            max_features=0.5\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    logreg.fit(X_train, y_train)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    proba_lr = logreg.predict_proba(X_test)[:, 1]\n",
    "    proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    ap_lr = average_precision_score(y_test, proba_lr)\n",
    "    ap_rf = average_precision_score(y_test, proba_rf)\n",
    "\n",
    "    p_lr, r_lr, _ = precision_recall_at_k(y_test, proba_lr, topk_frac)\n",
    "    p_rf, r_rf, _ = precision_recall_at_k(y_test, proba_rf, topk_frac)\n",
    "\n",
    "    return {\n",
    "        \"logreg\": {\"ap\": float(ap_lr), \"p10\": p_lr, \"r10\": r_lr},\n",
    "        \"rf\":     {\"ap\": float(ap_rf), \"p10\": p_rf, \"r10\": r_rf},\n",
    "        \"models\": {\"logreg\": logreg, \"rf\": rf},\n",
    "        \"split\":  {\"X_test\": X_test, \"y_test\": y_test},\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6baf05",
   "metadata": {},
   "source": [
    "## -------------------------\n",
    "## Baseline / No-Price / Bill pressure\n",
    "## -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a74fc0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BASELINE\n",
      "LogReg: {'ap': 0.16989527046610545, 'p10': 0.23013698630136986, 'r10': 0.23661971830985915} \n",
      "RF   : {'ap': 0.3273387622568088, 'p10': 0.3424657534246575, 'r10': 0.352112676056338}\n",
      "\n",
      "NO-PRICE\n",
      "LogReg: {'ap': 0.16381251776475558, 'p10': 0.2136986301369863, 'r10': 0.21971830985915494} \n",
      "RF   : {'ap': 0.3233785961880004, 'p10': 0.33972602739726027, 'r10': 0.3492957746478873}\n",
      "\n",
      "WITH BILL PRESSURE\n",
      "LogReg: {'ap': 0.17092991253327736, 'p10': 0.20821917808219179, 'r10': 0.2140845070422535} \n",
      "RF   : {'ap': 0.33260253643101256, 'p10': 0.336986301369863, 'r10': 0.3464788732394366}\n"
     ]
    }
   ],
   "source": [
    "base = train_eval_models(X_log, y, random_state=RANDOM_STATE, test_size=TEST_SIZE, topk_frac=TOPK_FRAC)\n",
    "print(\"\\nBASELINE\\nLogReg:\", base[\"logreg\"], \"\\nRF   :\", base[\"rf\"])\n",
    "\n",
    "price_cols = [c for c in X_log.columns if c.startswith(\"price_\") or \"peak_minus\" in c or \"peak_over\" in c]\n",
    "X_noprice = X_log.drop(columns=price_cols, errors=\"ignore\")\n",
    "nop = train_eval_models(X_noprice, y, random_state=RANDOM_STATE, test_size=TEST_SIZE, topk_frac=TOPK_FRAC)\n",
    "print(\"\\nNO-PRICE\\nLogReg:\", nop[\"logreg\"], \"\\nRF   :\", nop[\"rf\"])\n",
    "\n",
    "X_bill = X_log.copy()\n",
    "# bill pressure (usa consumi/potenza RAW o log? meglio RAW)\n",
    "# Qui usiamo le colonne RAW originali (da X) per coerenza economica:\n",
    "if \"price_off_peak_var_last\" in X_bill.columns and \"cons_12m\" in X.columns:\n",
    "    X_bill[\"bill_var_off_last_x_cons12m\"] = X_bill[\"price_off_peak_var_last\"] * X[\"cons_12m\"]\n",
    "if \"price_peak_var_last\" in X_bill.columns and \"cons_12m\" in X.columns:\n",
    "    X_bill[\"bill_var_peak_last_x_cons12m\"] = X_bill[\"price_peak_var_last\"] * X[\"cons_12m\"]\n",
    "if \"price_off_peak_fix_last\" in X_bill.columns and \"pow_max\" in X.columns:\n",
    "    X_bill[\"bill_fix_off_last_x_pow\"] = X_bill[\"price_off_peak_fix_last\"] * X[\"pow_max\"]\n",
    "\n",
    "X_bill = sanitize_inf(X_bill)\n",
    "\n",
    "bil = train_eval_models(X_bill, y, random_state=RANDOM_STATE, test_size=TEST_SIZE, topk_frac=TOPK_FRAC)\n",
    "print(\"\\nWITH BILL PRESSURE\\nLogReg:\", bil[\"logreg\"], \"\\nRF   :\", bil[\"rf\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42030847",
   "metadata": {},
   "source": [
    "## -------------------------\n",
    "## CV comparativa (RF)\n",
    "## -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dad17bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV TABLE\n",
      "             set   AP_mean    AP_std  P@k_mean  R@k_mean\n",
      "2  bill_pressure  0.321534  0.008754  0.314384  0.323466\n",
      "0       baseline  0.316913  0.008343  0.313699  0.322762\n",
      "1       no_price  0.304349  0.008679  0.309589  0.318529\n"
     ]
    }
   ],
   "source": [
    "def make_rf_pipeline(Xtr):\n",
    "    preprocess = build_preprocess(Xtr)\n",
    "    return Pipeline(steps=[\n",
    "        (\"prep\", preprocess),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            n_estimators=400,\n",
    "            random_state=RANDOM_STATE,\n",
    "            class_weight=\"balanced_subsample\",\n",
    "            n_jobs=-1,\n",
    "            min_samples_leaf=5,\n",
    "            max_features=0.5\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "def cv_compare_sets(feature_sets: dict, y_in, n_splits=5, random_state=42, topk_frac=0.10):\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    rows = []\n",
    "    for name, Xset in feature_sets.items():\n",
    "        Xset = sanitize_inf(Xset)\n",
    "        aps, pks, rks = [], [], []\n",
    "        for tr, te in cv.split(Xset, y_in):\n",
    "            Xtr, Xte = Xset.iloc[tr], Xset.iloc[te]\n",
    "            ytr, yte = y_in.iloc[tr], y_in.iloc[te]\n",
    "            model = make_rf_pipeline(Xtr)\n",
    "            model.fit(Xtr, ytr)\n",
    "            proba = model.predict_proba(Xte)[:, 1]\n",
    "            aps.append(average_precision_score(yte, proba))\n",
    "            p_k, r_k, _ = precision_recall_at_k(yte, proba, topk_frac)\n",
    "            pks.append(p_k); rks.append(r_k)\n",
    "        rows.append({\n",
    "            \"set\": name,\n",
    "            \"AP_mean\": float(np.mean(aps)),\n",
    "            \"AP_std\": float(np.std(aps)),\n",
    "            \"P@k_mean\": float(np.mean(pks)),\n",
    "            \"R@k_mean\": float(np.mean(rks)),\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"AP_mean\", ascending=False)\n",
    "\n",
    "feature_sets = {\"baseline\": X_log, \"no_price\": X_noprice, \"bill_pressure\": X_bill}\n",
    "cv_table = cv_compare_sets(feature_sets, y, n_splits=5, random_state=RANDOM_STATE, topk_frac=TOPK_FRAC)\n",
    "print(\"\\nCV TABLE\")\n",
    "print(cv_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b388e",
   "metadata": {},
   "source": [
    "## -------------------------\n",
    "## Altri parametri\n",
    "## -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cb83e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "min_samples_leaf",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "max_features",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "AP_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AP_std",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "P@k_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R@k_mean",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "32457ee8-f2af-40a2-903b-616c9c98ea0f",
       "rows": [
        [
         "1",
         "1",
         "0.5",
         "0.3238704465044432",
         "0.009957320171806545",
         "0.22397260273972605",
         "0.46088687602647693"
        ],
        [
         "3",
         "5",
         "0.5",
         "0.3215341131472756",
         "0.008754291779871103",
         "0.22842465753424662",
         "0.47005424774797194"
        ],
        [
         "0",
         "1",
         "sqrt",
         "0.31088543931061247",
         "0.010505553133038987",
         "0.22294520547945207",
         "0.4587617578261086"
        ],
        [
         "5",
         "10",
         "0.5",
         "0.3100076343338924",
         "0.011681556328920907",
         "0.2328767123287671",
         "0.479221619469467"
        ],
        [
         "2",
         "5",
         "sqrt",
         "0.2967120747842764",
         "0.005145529596395897",
         "0.225",
         "0.46301945951326334"
        ],
        [
         "4",
         "10",
         "sqrt",
         "0.28006760699688193",
         "0.01110867502334629",
         "0.2232876712328767",
         "0.4594883790374757"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>AP_mean</th>\n",
       "      <th>AP_std</th>\n",
       "      <th>P@k_mean</th>\n",
       "      <th>R@k_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.323870</td>\n",
       "      <td>0.009957</td>\n",
       "      <td>0.223973</td>\n",
       "      <td>0.460887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.321534</td>\n",
       "      <td>0.008754</td>\n",
       "      <td>0.228425</td>\n",
       "      <td>0.470054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.310885</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.222945</td>\n",
       "      <td>0.458762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.310008</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.479222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.296712</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.463019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.280068</td>\n",
       "      <td>0.011109</td>\n",
       "      <td>0.223288</td>\n",
       "      <td>0.459488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_samples_leaf max_features   AP_mean    AP_std  P@k_mean  R@k_mean\n",
       "1                 1          0.5  0.323870  0.009957  0.223973  0.460887\n",
       "3                 5          0.5  0.321534  0.008754  0.228425  0.470054\n",
       "0                 1         sqrt  0.310885  0.010506  0.222945  0.458762\n",
       "5                10          0.5  0.310008  0.011682  0.232877  0.479222\n",
       "2                 5         sqrt  0.296712  0.005146  0.225000  0.463019\n",
       "4                10         sqrt  0.280068  0.011109  0.223288  0.459488"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "def rf_cv_tiny_grid(X_in, y_in, n_splits=5, random_state=42, k_frac=0.20):\n",
    "    X_in = sanitize_inf(X_in)\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    grid = {\n",
    "        \"min_samples_leaf\": [1, 5, 10],\n",
    "        \"max_features\": [\"sqrt\", 0.5],\n",
    "    }\n",
    "\n",
    "    rows = []\n",
    "    for msl, mf in product(grid[\"min_samples_leaf\"], grid[\"max_features\"]):\n",
    "        aps, pks, rks = [], [], []\n",
    "\n",
    "        for tr, te in cv.split(X_in, y_in):\n",
    "            Xtr, Xte = X_in.iloc[tr], X_in.iloc[te]\n",
    "            ytr, yte = y_in.iloc[tr], y_in.iloc[te]\n",
    "\n",
    "            preprocess = build_preprocess(Xtr)\n",
    "            model = Pipeline(steps=[\n",
    "                (\"prep\", preprocess),\n",
    "                (\"clf\", RandomForestClassifier(\n",
    "                    n_estimators=400,\n",
    "                    random_state=random_state,\n",
    "                    class_weight=\"balanced_subsample\",\n",
    "                    n_jobs=-1,\n",
    "                    min_samples_leaf=msl,\n",
    "                    max_features=mf\n",
    "                ))\n",
    "            ])\n",
    "\n",
    "            model.fit(Xtr, ytr)\n",
    "            proba = model.predict_proba(Xte)[:, 1]\n",
    "\n",
    "            aps.append(average_precision_score(yte, proba))\n",
    "            p_k, r_k, _ = precision_recall_at_k(yte, proba, k_frac)\n",
    "            pks.append(p_k); rks.append(r_k)\n",
    "\n",
    "        rows.append({\n",
    "            \"min_samples_leaf\": msl,\n",
    "            \"max_features\": mf,\n",
    "            \"AP_mean\": float(np.mean(aps)),\n",
    "            \"AP_std\": float(np.std(aps)),\n",
    "            \"P@k_mean\": float(np.mean(pks)),\n",
    "            \"R@k_mean\": float(np.mean(rks)),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(\"AP_mean\", ascending=False)\n",
    "\n",
    "# Esempio: tuning sul set finale\n",
    "grid_res = rf_cv_tiny_grid(X_bill, y, n_splits=5, random_state=RANDOM_STATE, k_frac=0.20)\n",
    "grid_res.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e94b7",
   "metadata": {},
   "source": [
    "## -------------------------\n",
    "## Final model + lift table\n",
    "## -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d3d7e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LIFT TABLE (test)\n",
      "   contact_frac     k  precision    recall  lift_vs_base\n",
      "0          0.01    36   0.861111  0.087324      8.858529\n",
      "1          0.02    73   0.671233  0.138028      6.905190\n",
      "2          0.05   182   0.483516  0.247887      4.974091\n",
      "3          0.10   365   0.336986  0.346479      3.466687\n",
      "4          0.15   547   0.277879  0.428169      2.858635\n",
      "5          0.20   730   0.231507  0.476056      2.381586\n",
      "6          0.30  1095   0.196347  0.605634      2.019886\n"
     ]
    }
   ],
   "source": [
    "def lift_table(y_true, y_score, fracs=(0.01,0.02,0.05,0.10,0.15,0.20,0.30)):\n",
    "    base_rate = float(pd.Series(y_true).mean())\n",
    "    rows = []\n",
    "    for f in fracs:\n",
    "        p, r, k = precision_recall_at_k(y_true, y_score, f)\n",
    "        rows.append({\n",
    "            \"contact_frac\": f, \"k\": k,\n",
    "            \"precision\": p, \"recall\": r,\n",
    "            \"lift_vs_base\": (p / base_rate) if base_rate > 0 else np.nan\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "X_final = X_bill\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_final, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "final_model = make_rf_pipeline(X_train)\n",
    "final_model.fit(X_train, y_train)\n",
    "proba_test = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "lift = lift_table(y_test, proba_test)\n",
    "print(\"\\nLIFT TABLE (test)\")\n",
    "print(lift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50d39e8",
   "metadata": {},
   "source": [
    "## -------------------------\n",
    "## Permutation importance\n",
    "## -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44ba736f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOP 20 PERMUTATION IMPORTANCE\n",
      "                        feature  perm_importance\n",
      "7            margin_net_pow_ele         0.120303\n",
      "6          margin_gross_pow_ele         0.067551\n",
      "15              days_to_renewal         0.067367\n",
      "11                    origin_up         0.035805\n",
      "13                  tenure_days         0.021623\n",
      "14        days_since_prod_modif         0.015549\n",
      "47      bill_fix_off_last_x_pow         0.013943\n",
      "16                   dev_consum         0.011537\n",
      "9                    net_margin         0.010241\n",
      "44               net_margin_log         0.010001\n",
      "3               cons_last_month         0.008952\n",
      "12                      pow_max         0.006618\n",
      "45  bill_var_off_last_x_cons12m         0.006212\n",
      "0                 channel_sales         0.005867\n",
      "1                      cons_12m         0.005637\n",
      "20     price_off_peak_var_slope         0.003938\n",
      "19       price_off_peak_var_std         0.003771\n",
      "32     price_off_peak_fix_slope         0.002912\n",
      "31       price_off_peak_fix_std         0.002244\n",
      "5                      imp_cons         0.002008\n"
     ]
    }
   ],
   "source": [
    "pi_final = permutation_importance(\n",
    "    final_model, X_test, y_test,\n",
    "    n_repeats=10, random_state=RANDOM_STATE,\n",
    "    scoring=\"average_precision\"\n",
    ")\n",
    "\n",
    "imp_final = pd.DataFrame({\n",
    "    \"feature\": X_test.columns,\n",
    "    \"perm_importance\": pi_final.importances_mean\n",
    "}).sort_values(\"perm_importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTOP 20 PERMUTATION IMPORTANCE\")\n",
    "print(imp_final.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9b8ca2",
   "metadata": {},
   "source": [
    "## -------------------------\n",
    "## CV robusta (manuale, P@20 e R@20)\n",
    "## -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9533b55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV ROBUSTA (bill_pressure, k=20%)\n",
      "Fold 1: AP=0.3223 | P@20%=0.238 | R@20%=0.489\n",
      "Fold 2: AP=0.3314 | P@20%=0.238 | R@20%=0.489\n",
      "Fold 3: AP=0.3288 | P@20%=0.224 | R@20%=0.461\n",
      "Fold 4: AP=0.3066 | P@20%=0.211 | R@20%=0.433\n",
      "Fold 5: AP=0.3186 | P@20%=0.231 | R@20%=0.477\n",
      "{'AP_mean': 0.3215341131472756, 'AP_std': 0.008754291779871103, 'P@k_mean': 0.22842465753424662, 'R@k_mean': 0.47005424774797194}\n"
     ]
    }
   ],
   "source": [
    "def cv_ap_and_recallk_manual(X_in, y_in, k_frac=0.20, n_splits=5, random_state=42):\n",
    "    X_in = sanitize_inf(X_in)\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    aps, pks, rks = [], [], []\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_in, y_in), 1):\n",
    "        Xtr, Xte = X_in.iloc[tr], X_in.iloc[te]\n",
    "        ytr, yte = y_in.iloc[tr], y_in.iloc[te]\n",
    "\n",
    "        model = make_rf_pipeline(Xtr)\n",
    "        model.fit(Xtr, ytr)\n",
    "        proba = model.predict_proba(Xte)[:, 1]\n",
    "\n",
    "        ap = average_precision_score(yte, proba)\n",
    "        p_k, r_k, _ = precision_recall_at_k(yte, proba, k_frac)\n",
    "\n",
    "        aps.append(ap); pks.append(p_k); rks.append(r_k)\n",
    "        print(f\"Fold {fold}: AP={ap:.4f} | P@{int(k_frac*100)}%={p_k:.3f} | R@{int(k_frac*100)}%={r_k:.3f}\")\n",
    "\n",
    "    return {\n",
    "        \"AP_mean\": float(np.mean(aps)),\n",
    "        \"AP_std\": float(np.std(aps)),\n",
    "        \"P@k_mean\": float(np.mean(pks)),\n",
    "        \"R@k_mean\": float(np.mean(rks)),\n",
    "    }\n",
    "\n",
    "print(\"\\nCV ROBUSTA (bill_pressure, k=20%)\")\n",
    "cv_stats = cv_ap_and_recallk_manual(X_final, y, k_frac=0.20, n_splits=5, random_state=RANDOM_STATE)\n",
    "print(cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bbc12b",
   "metadata": {},
   "source": [
    "## -------------------------\n",
    "## Business case (policy a due livelli) - usa net_margin RAW da df\n",
    "## -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f50f7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BUSINESS CASE (policy)\n",
      "Top-20% targeted: 730\n",
      "Offer recommended count: 243 (33.29%)\n",
      "Expected churn prevented (uplift): 27.3692243125151\n",
      "Total cost (policy): 632.0\n",
      "Total benefit (proxy): 1607.224330688525\n",
      "Net expected value: 975.224330688525\n"
     ]
    }
   ],
   "source": [
    "q = df[\"net_margin\"].quantile([0.99]).to_dict()\n",
    "CAP = float(q[0.99])\n",
    "\n",
    "K_FRAC = 0.20\n",
    "ALPHA = 0.3\n",
    "UPLIFT_ASSUMED = 0.10\n",
    "LOW_COST_CONTACT = 0.2\n",
    "OFFER_COST = 2.0\n",
    "\n",
    "idx = X_test.index\n",
    "d = df.loc[idx, [\"net_margin\", \"churn\"]].copy()\n",
    "\n",
    "d[\"net_margin_cap\"] = d[\"net_margin\"].clip(lower=0, upper=CAP)\n",
    "d[\"p_churn\"] = proba_test\n",
    "d[\"residual_value\"] = ALPHA * d[\"net_margin_cap\"]\n",
    "\n",
    "k = max(1, int(len(d) * K_FRAC))\n",
    "sel = np.argsort(-d[\"p_churn\"].values)[:k]\n",
    "tgt2 = d.iloc[sel].copy()\n",
    "\n",
    "tgt2[\"max_total_cost_break_even\"] = tgt2[\"p_churn\"] * UPLIFT_ASSUMED * tgt2[\"residual_value\"]\n",
    "tgt2[\"offer_recommended\"] = tgt2[\"max_total_cost_break_even\"] >= (LOW_COST_CONTACT + OFFER_COST)\n",
    "\n",
    "offer_count = int(tgt2[\"offer_recommended\"].sum())\n",
    "total_target = len(tgt2)\n",
    "\n",
    "expected_churn_in_target = float(tgt2[\"p_churn\"].sum())\n",
    "expected_churn_prevented = expected_churn_in_target * UPLIFT_ASSUMED\n",
    "\n",
    "total_cost = (total_target * LOW_COST_CONTACT) + (offer_count * OFFER_COST)\n",
    "total_benefit = float((tgt2[\"p_churn\"] * UPLIFT_ASSUMED * tgt2[\"residual_value\"]).sum())\n",
    "\n",
    "print(\"\\nBUSINESS CASE (policy)\")\n",
    "print(\"Top-20% targeted:\", total_target)\n",
    "print(\"Offer recommended count:\", offer_count, f\"({offer_count/total_target:.2%})\")\n",
    "print(\"Expected churn prevented (uplift):\", expected_churn_prevented)\n",
    "print(\"Total cost (policy):\", total_cost)\n",
    "print(\"Total benefit (proxy):\", total_benefit)\n",
    "print(\"Net expected value:\", total_benefit - total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a13b13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold (contact+offer): 2.2\n",
      "Offer rate: 0.33287671232876714\n",
      "\n",
      "--- TARGET SUMMARY (top-20%) ---\n",
      "p_churn mean: 0.3749208809933575\n",
      "p_churn median: 0.33973042061037806\n",
      "net_margin_cap mean: 197.01063493150684\n",
      "net_margin_cap median: 124.535\n",
      "residual_value mean: 59.10319047945205\n",
      "\n",
      "Avg gap to threshold (non-recommended): 1.3072663448154918\n",
      "\n",
      "max_total_cost_break_even quantiles:\n",
      "0.10     0.249226\n",
      "0.25     0.594694\n",
      "0.50     1.343122\n",
      "0.75     2.909904\n",
      "0.90     5.669452\n",
      "0.95     7.124058\n",
      "0.99    10.634786\n",
      "Name: max_total_cost_break_even, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "thr = LOW_COST_CONTACT + OFFER_COST\n",
    "\n",
    "print(\"Threshold (contact+offer):\", thr)\n",
    "print(\"Offer rate:\", tgt2[\"offer_recommended\"].mean())\n",
    "\n",
    "# Diagnosi delle leve\n",
    "print(\"\\n--- TARGET SUMMARY (top-20%) ---\")\n",
    "print(\"p_churn mean:\", tgt2[\"p_churn\"].mean())\n",
    "print(\"p_churn median:\", tgt2[\"p_churn\"].median())\n",
    "print(\"net_margin_cap mean:\", tgt2[\"net_margin_cap\"].mean())\n",
    "print(\"net_margin_cap median:\", tgt2[\"net_margin_cap\"].median())\n",
    "print(\"residual_value mean:\", tgt2[\"residual_value\"].mean())\n",
    "\n",
    "# Quanto manca in media ai NON raccomandati per diventarlo?\n",
    "gap = thr - tgt2.loc[~tgt2[\"offer_recommended\"], \"max_total_cost_break_even\"]\n",
    "print(\"\\nAvg gap to threshold (non-recommended):\", gap.mean())\n",
    "\n",
    "# Distribuzione break-even vs soglia\n",
    "print(\"\\nmax_total_cost_break_even quantiles:\")\n",
    "print(tgt2[\"max_total_cost_break_even\"].quantile([0.1,0.25,0.5,0.75,0.9,0.95,0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23e3e5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    p_churn  net_margin_cap  residual_value  \\\n",
      "offer_recommended                                             \n",
      "False              0.360178       86.520000        25.95600   \n",
      "True               0.404468      418.446599       125.53398   \n",
      "\n",
      "                   max_total_cost_break_even  \n",
      "offer_recommended                             \n",
      "False                               0.892734  \n",
      "True                                4.824951  \n"
     ]
    }
   ],
   "source": [
    "# Confronto recommended vs non\n",
    "grp = tgt2.groupby(\"offer_recommended\")[[\"p_churn\",\"net_margin_cap\",\"residual_value\",\"max_total_cost_break_even\"]].mean()\n",
    "print(grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93deb9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "offer_recommended",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "churn",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "972ea314-95f9-4811-8807-d313a39d3945",
       "rows": [
        [
         "False",
         "0.21149897330595482"
        ],
        [
         "True",
         "0.2716049382716049"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "offer_recommended\n",
       "False    0.211499\n",
       "True     0.271605\n",
       "Name: churn, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt2.groupby(\"offer_recommended\")[\"churn\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de899498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.2602739726027397),\n",
       " offer_recommended_v2\n",
       " False    0.200000\n",
       " True     0.321053\n",
       " Name: churn, dtype: float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_MIN = 0.30  # esempio, da tarare\n",
    "tgt2[\"offer_recommended_v2\"] = (\n",
    "    (tgt2[\"max_total_cost_break_even\"] >= (LOW_COST_CONTACT + OFFER_COST)) &\n",
    "    (tgt2[\"p_churn\"] >= P_MIN)\n",
    ")\n",
    "tgt2[\"offer_recommended_v2\"].mean(), tgt2.groupby(\"offer_recommended_v2\")[\"churn\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6889b21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "offer_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "offer_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_target",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_cost",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "benefit_email",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "benefit_offer",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_benefit",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "net_ev",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "churn_true",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "churn_false",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c3bef2e0-40cf-4afc-b6df-81088aea057b",
       "rows": [
        [
         "v1_break_even",
         "0.33287671232876714",
         "243",
         "730",
         "632.0",
         "321.444866137705",
         "937.9704324909355",
         "1259.4152986286406",
         "627.4152986286406",
         "0.2716049382716049",
         "0.21149897330595482"
        ],
        [
         "v2_break_even+pmin",
         "0.2602739726027397",
         "190",
         "730",
         "526.0",
         "321.444866137705",
         "763.2005936173286",
         "1084.6454597550337",
         "558.6454597550337",
         "0.32105263157894737",
         "0.2"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offer_rate</th>\n",
       "      <th>offer_count</th>\n",
       "      <th>total_target</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>benefit_email</th>\n",
       "      <th>benefit_offer</th>\n",
       "      <th>total_benefit</th>\n",
       "      <th>net_ev</th>\n",
       "      <th>churn_true</th>\n",
       "      <th>churn_false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>v1_break_even</th>\n",
       "      <td>0.332877</td>\n",
       "      <td>243</td>\n",
       "      <td>730</td>\n",
       "      <td>632.0</td>\n",
       "      <td>321.444866</td>\n",
       "      <td>937.970432</td>\n",
       "      <td>1259.415299</td>\n",
       "      <td>627.415299</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.211499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v2_break_even+pmin</th>\n",
       "      <td>0.260274</td>\n",
       "      <td>190</td>\n",
       "      <td>730</td>\n",
       "      <td>526.0</td>\n",
       "      <td>321.444866</td>\n",
       "      <td>763.200594</td>\n",
       "      <td>1084.645460</td>\n",
       "      <td>558.645460</td>\n",
       "      <td>0.321053</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    offer_rate  offer_count  total_target  total_cost  \\\n",
       "v1_break_even         0.332877          243           730       632.0   \n",
       "v2_break_even+pmin    0.260274          190           730       526.0   \n",
       "\n",
       "                    benefit_email  benefit_offer  total_benefit      net_ev  \\\n",
       "v1_break_even          321.444866     937.970432    1259.415299  627.415299   \n",
       "v2_break_even+pmin     321.444866     763.200594    1084.645460  558.645460   \n",
       "\n",
       "                    churn_true  churn_false  \n",
       "v1_break_even         0.271605     0.211499  \n",
       "v2_break_even+pmin    0.321053     0.200000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UPLIFT_EMAIL = 0.02        # esempio: uplift piccolo da contatto\n",
    "UPLIFT_OFFER_INC = 0.08    # esempio: uplift addizionale dell'incentivo\n",
    "# (totale offer = 0.02 + 0.08 = 0.10)\n",
    "\n",
    "def eval_policy_fixed(tgt, flag_col):\n",
    "    offer_mask = tgt[flag_col].astype(bool)\n",
    "\n",
    "    # costi\n",
    "    total_target = len(tgt)\n",
    "    offer_count = int(offer_mask.sum())\n",
    "    total_cost = (total_target * LOW_COST_CONTACT) + (offer_count * OFFER_COST)\n",
    "\n",
    "    # benefici: email su tutti + incentivo solo su recommended\n",
    "    benefit_email = float((tgt[\"p_churn\"] * UPLIFT_EMAIL * tgt[\"residual_value\"]).sum())\n",
    "    benefit_offer = float((tgt.loc[offer_mask, \"p_churn\"] * UPLIFT_OFFER_INC * tgt.loc[offer_mask, \"residual_value\"]).sum())\n",
    "    total_benefit = benefit_email + benefit_offer\n",
    "    net_ev = total_benefit - total_cost\n",
    "\n",
    "    return {\n",
    "        \"offer_rate\": offer_count / total_target,\n",
    "        \"offer_count\": offer_count,\n",
    "        \"total_target\": total_target,\n",
    "        \"total_cost\": total_cost,\n",
    "        \"benefit_email\": benefit_email,\n",
    "        \"benefit_offer\": benefit_offer,\n",
    "        \"total_benefit\": total_benefit,\n",
    "        \"net_ev\": net_ev,\n",
    "        \"churn_true\": float(tgt.loc[offer_mask, \"churn\"].mean()) if offer_count > 0 else np.nan,\n",
    "        \"churn_false\": float(tgt.loc[~offer_mask, \"churn\"].mean()) if offer_count < total_target else np.nan,\n",
    "    }\n",
    "\n",
    "res_v1 = eval_policy_fixed(tgt2, \"offer_recommended\")\n",
    "res_v2 = eval_policy_fixed(tgt2, \"offer_recommended_v2\")\n",
    "\n",
    "pd.DataFrame([res_v1, res_v2], index=[\"v1_break_even\", \"v2_break_even+pmin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9f986f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68.769838873607, 53, 1.2975441296906982)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_ev = 627.41529862864 - 558.645459755033\n",
    "delta_offers = 243 - 190\n",
    "delta_ev_per_extra_offer = delta_ev / delta_offers\n",
    "delta_ev, delta_offers, delta_ev_per_extra_offer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bd4488",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------------\n",
    "# Conclusione del notebook\n",
    "## -----------------------------------------------------------\n",
    "In questo notebook abbiamo costruito un dataset “snapshot” **as-of T = 31/12/2015**, creando feature **senza leakage**: aggregazioni dei prezzi fino a T (last/mean/std/slope per ciascuna tariffa) e feature temporali lato cliente (tenure, giorni da modifica prodotto, giorni al rinnovo) più una proxy di deviazione dei consumi (dev_consum) calcolata per tutti i clienti. Il merge finale produce un dataset feature-ready di 14.606 righe (clienti) con feature numeriche/categoriche e variabili prezzo aggregate.\n",
    "\n",
    "Sul modelling abbiamo confrontato tre set di feature (**baseline, no_price, bill_pressure**) con metriche adatte a class imbalance (churn rate ≈**9.7%**) e validazione cross-validation. La Random Forest è stata leggermente regolarizzata tramite tuning minimale (scelta finale: min_samples_leaf=5, max_features=0.5, n_estimators=400, class_weight=\"balanced_subsample\"), privilegiando stabilità e performance operative sul top-k. Il set **bill_pressure** (proxy dell’impatto economico: prezzo×consumo/potenza) risulta il migliore e stabile: **CV AP_mean ≈ 0.3215** (std ≈ 0.0088), superiore a baseline (≈ 0.3169) e no_price (≈ 0.3043).\n",
    "\n",
    "In ottica operativa, adottiamo una strategia **top-k**: sul test set, contattando il **top-20%** (730 clienti) otteniamo **precision ≈ 0.2315, recall ≈ 0.4761** (lift ≈ 2.38×), cioè quasi metà dei churner è intercettata concentrando l’azione su un quinto della base.\n",
    "\n",
    "Per la parte di business case abbiamo trasformato il ranking in una policy a due livelli: **email low-cost a tutto il top-20%** e **micro-incentivo selettivo** solo dove conviene economicamente. La selezione dell’offerta è guidata soprattutto dal valore cliente (net margin cappato al 99° percentile), e infatti i clienti “offer recommended” hanno churn osservato più alto (≈ 27.2% vs 21.1%) e valore medio molto superiore. Come raffinamento, l’aggiunta di una soglia minima di rischio (p_churn ≥ 0.30) aumenta la “purezza” del gruppo incentivato (≈ 32.1% churn osservato) riducendo il numero di incentivi. Nel confronto scenario-based con uplift separato (es. email 2% + incentivo addizionale 8%), la policy **v1 (solo break-even**)** massimizza l’EV atteso (≈ **+627**) ma richiede ~33% incentivi nel target; la policy **v2 (break-even + soglia rischio)** riduce gli incentivi (~26%) ma produce EV totale inferiore (≈ **+559**). La scelta finale dipende da vincoli di budget/capacità: senza vincoli espliciti v1 è preferibile, mentre v2 è una valida alternativa più parsimoniosa.\n",
    "\n",
    "***(Nota metodologica: la ROI resta scenario-based e dipende da uplift e dalla calibrazione delle probabilità; in produzione andrebbe validata con A/B test e, se necessario, con calibrazione delle proba.)***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
